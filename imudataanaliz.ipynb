{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data IMU CSV dan dibersihkan tahap 1###\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "# Baca data CSV\n",
    "df = pd.read_excel('imu_data_baru.xlsx')\n",
    "\n",
    "# 1. Tampilkan info umum data\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# 2. Buang kolom yang tidak relevan (ganti 'kolom_tidak_dipakai' sesuai kebutuhan)\n",
    "# df.drop(columns=['kolom_tidak_dipakai'], inplace=True)\n",
    "\n",
    "# 3. Tangani nilai hilang (missing values)\n",
    "# Contoh: isi dengan median, hapus, atau metode lain\n",
    "# df = df.dropna()  # jika ingin langsung membuang baris yang ada NaN\n",
    "# df['kolom_angka'] = df['kolom_angka'].fillna(df['kolom_angka'].median())\n",
    "\n",
    "# 4. Bersihkan data string, misalnya hapus spasi putih atau ubah ke lowercase\n",
    "# df['nama_kolom'] = df['nama_kolom'].str.strip().str.lower()\n",
    "\n",
    "# 5. Ubah tipe data jika perlu\n",
    "# df['tanggal'] = pd.to_datetime(df['tanggal'], errors='coerce')\n",
    "# df['angka'] = pd.to_numeric(df['angka'], errors='coerce')\n",
    "\n",
    "# 6. Buang duplikat\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 7. Simpan data yang sudah dibersihkan\n",
    "df.to_csv('data_imu_clean1.csv', index=False)\n",
    "print(\"Data berhasil dibersihkan dan disimpan sebagai 'data_imu_clean1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b68195",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pembersihan data tahap 2 \n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV dan paksa semua nilai ke bentuk numerik\n",
    "df = pd.read_csv(\"data_imu_clean1.csv\")\n",
    "\n",
    "# Buang spasi putih di awal/akhir sel\n",
    "df = df.applymap(lambda x: str(x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Konversi semua kolom ke numeric jika bisa, dan paksa NaN jika gagal\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop baris dengan NaN akibat parsing gagal\n",
    "df.dropna(inplace=True)\n",
    "df.to_csv(\"data_imu_oke.csv\", index=False)\n",
    "print(\" File bersih disimpan sebagai: data_imu_oke.csv\")\n",
    "\n",
    "print(\" Data berhasil dibersihkan dari nilai yang tidak bisa dikonversi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualisasi data IMU\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Baca file CSV\n",
    "df = pd.read_csv(\"data_imu_oke.csv\")\n",
    "\n",
    "# Tampilkan label unik\n",
    "print(\"Label yang ditemukan:\", df['label'].unique())\n",
    "\n",
    "# Loop visualisasi per label\n",
    "for label in sorted(df['label'].unique()):\n",
    "    subset = df[df['label'] == label].reset_index(drop=True)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "    fig.suptitle(f'Sinyal IMU - Label {label}', fontsize=16)\n",
    "\n",
    "    # Akselerometer\n",
    "    axs[0].plot(subset['ax'], label='Ax', alpha=0.7)\n",
    "    axs[0].plot(subset['ay'], label='Ay', alpha=0.7)\n",
    "    axs[0].plot(subset['az'], label='Az', alpha=0.7)\n",
    "    axs[0].set_ylabel('Accelerometer (g)')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Gyroscope\n",
    "    axs[1].plot(subset['gx'], label='Gx', alpha=0.7)\n",
    "    axs[1].plot(subset['gy'], label='Gy', alpha=0.7)\n",
    "    axs[1].plot(subset['gz'], label='Gz', alpha=0.7)\n",
    "    axs[1].set_ylabel('Gyroscope (Â°/s)')\n",
    "    axs[1].set_xlabel('Index Sampel')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbc366",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.iloc[:300]  # atau nilai yang sesuai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12092db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0].plot(subset['ax'], label='Ax', color='red')\n",
    "axs[0].plot(subset['ay'], label='Ay', color='green')\n",
    "axs[0].plot(subset['az'], label='Az', color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ekstraksi Fitur per window IMU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def extract_features_from_imu(\n",
    "    filepath,\n",
    "    fs=50,\n",
    "    window_duration=2,\n",
    "    stride_ratio=1.0,\n",
    "    axis_cols=['ax', 'ay', 'az', 'gx', 'gy', 'gz'],\n",
    "    label_col='label'\n",
    "):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Konversi numerik\n",
    "    for col in axis_cols + [label_col]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df = df.dropna(subset=axis_cols + [label_col])\n",
    "\n",
    "    window_size = int(fs * window_duration)\n",
    "    stride = int(window_size * stride_ratio)\n",
    "    features = []\n",
    "\n",
    "    for start in range(0, len(df) - window_size + 1, stride):\n",
    "        end = start + window_size\n",
    "        window = df.iloc[start:end]\n",
    "        row = {}\n",
    "\n",
    "        for axis in axis_cols:\n",
    "            signal = window[axis]\n",
    "            row[f'{axis}_mean'] = signal.mean()\n",
    "            row[f'{axis}_std'] = signal.std()\n",
    "            row[f'{axis}_max'] = signal.max()\n",
    "            row[f'{axis}_min'] = signal.min()\n",
    "            row[f'{axis}_range'] = signal.max() - signal.min()\n",
    "            row[f'{axis}_rms'] = np.sqrt(np.mean(signal**2))\n",
    "            row[f'{axis}_energy'] = np.sum(signal**2)\n",
    "            row[f'{axis}_mad'] = np.mean(np.abs(signal - signal.mean()))\n",
    "\n",
    "        # Label mayoritas\n",
    "        dominant_label = Counter(window[label_col]).most_common(1)[0][0]\n",
    "        row['label'] = dominant_label\n",
    "        features.append(row)\n",
    "\n",
    "    return pd.DataFrame(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jalankan fungsi Ekstraksi Fitur per Window\n",
    "features_df = extract_features_from_imu(\n",
    "    filepath='data_imu_oke.csv',\n",
    "    fs=50,\n",
    "    window_duration=2,\n",
    "    stride_ratio=0.5  # 50% overlap\n",
    ")\n",
    "\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proses SVM _ RBF_ ConMatrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pisahkan fitur dan label\n",
    "X = features_df.drop(columns=['label'])\n",
    "y = features_df['label']\n",
    "\n",
    "# Normalisasi\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Pecah data (tanpa stratify kalau jumlah label tidak merata)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Latih model SVM dengan RBF kernel\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "print(\" Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - SVM RBF\")\n",
    "plt.xlabel(\"Prediksi\")\n",
    "plt.ylabel(\"Label Sebenarnya\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd888f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "def run_cv_pipeline(X, y, model_desc=\"SVM RBF\", C=1.0, gamma='scale', cv_strategy=None):\n",
    "    from sklearn.model_selection import cross_validate\n",
    "\n",
    "    if cv_strategy is None:\n",
    "        if len(y) < 10:\n",
    "            cv_strategy = LeaveOneOut()\n",
    "            cv_name = \"Leave-One-Out\"\n",
    "        else:\n",
    "            cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            cv_name = \"Stratified 5-Fold\"\n",
    "    else:\n",
    "        cv_name = str(cv_strategy)\n",
    "\n",
    "    clf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1_macro': make_scorer(f1_score, average='macro')\n",
    "    }\n",
    "\n",
    "    start = time.time()\n",
    "    scores = cross_validate(clf, X, y, cv=cv_strategy, scoring=scoring, return_train_score=False)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\" Model: {model_desc}\")\n",
    "    print(f\" Evaluasi: {cv_name}\")\n",
    "    print(f\" Akurasi Rerata: {scores['test_accuracy'].mean():.4f} Â± {scores['test_accuracy'].std():.4f}\")\n",
    "    print(f\" F1-score Macro: {scores['test_f1_macro'].mean():.4f}\")\n",
    "    print(f\" Durasi Evaluasi: {end - start:.2f} detik\")\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_scaled  # dari features_df\n",
    "scores_all = run_cv_pipeline(X_all, y, model_desc=\"SVM Semua Fitur\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cek ukuran total dan jumlah kolom\n",
    "print(\" Ukuran dataset:\", features_df.shape)\n",
    "\n",
    "# 2. Distribusi label\n",
    "print(\" Distribusi label:\")\n",
    "print(features_df['label'].value_counts())\n",
    "\n",
    "# 3. Apakah ada nilai NaN?\n",
    "print(\" Jumlah nilai kosong:\", features_df.isnull().sum().sum())\n",
    "\n",
    "# 4. Jumlah fitur numerik (exclude label)\n",
    "print(\" Jumlah fitur:\", features_df.drop(columns=['label']).shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "def fitness_function(params, X, y, cv=3):\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    results = []\n",
    "    for C, gamma in params:\n",
    "        clf = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "        score = cross_val_score(clf, X, y, cv=cv).mean()\n",
    "        results.append(-score)  # PSO minimize, so use negative\n",
    "    return np.array(results)\n",
    "\n",
    "\n",
    "def run_pso(X, y, n_particles=20, n_iter=50, cv=3):\n",
    "    import pyswarms as ps\n",
    "\n",
    "    # Boundaries for C and gamma\n",
    "    bounds = ([1e-3, 1e-5], [100, 10])\n",
    "\n",
    "    optimizer = ps.single.GlobalBestPSO(\n",
    "        n_particles=n_particles,\n",
    "        dimensions=2,\n",
    "        options={'c1': 0.5, 'c2': 0.3, 'w': 0.9},\n",
    "        bounds=bounds\n",
    "    )\n",
    "\n",
    "    best_cost, best_pos = optimizer.optimize(\n",
    "        fitness_function, n_iter, X=X, y=y, cv=cv\n",
    "    )\n",
    "\n",
    "    C_opt, gamma_opt = best_pos\n",
    "    print(f\" Optimal C: {C_opt:.4f}, gamma: {gamma_opt:.6f}\")\n",
    "    return C_opt, gamma_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aae99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = extract_features_from_imu(\n",
    "    filepath='data_imu_oke.csv',\n",
    "    fs=50,\n",
    "    window_duration=2,\n",
    "    stride_ratio=0.5  # 50% overlap\n",
    ")\n",
    "\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mulai PSO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def fitness_function(params, X, y, cv=3):\n",
    "    results = []\n",
    "    for C, gamma in params:\n",
    "        model = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "        scores = cross_val_score(model, X, y, cv=cv)\n",
    "        results.append(-scores.mean())  # PSO minimizes\n",
    "    return np.array(results)\n",
    "\n",
    "def run_svm_pso_pipeline(features_df, n_particles=20, n_iter=50, cv=3, save_csv=False, csv_path=\"svm_pso_log.csv\"):\n",
    "    import pyswarms as ps\n",
    "\n",
    "    # Step 1: Prepare features and labels\n",
    "    X = features_df.drop(columns=['label']).values\n",
    "    y = features_df['label'].values\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Step 2: PSO optimization\n",
    "    bounds = ([1e-3, 1e-5], [100, 10])  # lower, upper for C and gamma\n",
    "    optimizer = ps.single.GlobalBestPSO(\n",
    "        n_particles=n_particles,\n",
    "        dimensions=2,\n",
    "        options={'c1': 0.5, 'c2': 0.3, 'w': 0.9},\n",
    "        bounds=bounds\n",
    "    )\n",
    "    print(\" Menjalankan PSO untuk optimasi hyperparameter SVM...\")\n",
    "    best_cost, best_pos = optimizer.optimize(\n",
    "        fitness_function, n_iter, X=X_scaled, y=y, cv=cv\n",
    "    )\n",
    "    C_opt, gamma_opt = best_pos\n",
    "    print(f\" Optimal C: {C_opt:.4f}, gamma: {gamma_opt:.6f}\")\n",
    "\n",
    "    # Step 3: Evaluate model\n",
    "    clf = SVC(kernel='rbf', C=C_opt, gamma=gamma_opt)\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    all_scores = []\n",
    "    all_reports = []\n",
    "    all_conf_matrices = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_scaled, y), 1):\n",
    "        clf.fit(X_scaled[train_idx], y[train_idx])\n",
    "        y_pred = clf.predict(X_scaled[test_idx])\n",
    "        score = clf.score(X_scaled[test_idx], y[test_idx])\n",
    "        report = classification_report(y[test_idx], y_pred, zero_division=0, output_dict=True)\n",
    "        cm = confusion_matrix(y[test_idx], y_pred)\n",
    "\n",
    "        all_scores.append(score)\n",
    "        all_reports.append(report)\n",
    "        all_conf_matrices.append(cm)\n",
    "\n",
    "        print(f\"\\n Fold {fold} Report:\")\n",
    "        print(classification_report(y[test_idx], y_pred, zero_division=0))\n",
    "\n",
    "        # Confusion Matrix plot\n",
    "        plt.figure(figsize=(5,4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f\"Confusion Matrix - Fold {fold}\")\n",
    "        plt.xlabel(\"Prediksi\")\n",
    "        plt.ylabel(\"Label Sebenarnya\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Logging\n",
    "    result_df = pd.DataFrame({\n",
    "        \"Fold\": list(range(1, cv + 1)),\n",
    "        \"Accuracy\": all_scores\n",
    "    })\n",
    "    print(f\"\\n Akurasi Rata-rata CV: {np.mean(all_scores):.4f} Â± {np.std(all_scores):.4f}\")\n",
    "\n",
    "    if save_csv:\n",
    "        result_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Log hasil disimpan ke: {csv_path}\")\n",
    "\n",
    "    return {\n",
    "        \"C\": C_opt,\n",
    "        \"gamma\": gamma_opt,\n",
    "        \"scores\": all_scores,\n",
    "        \"reports\": all_reports,\n",
    "        \"conf_matrices\": all_conf_matrices\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_svm_pso_pipeline(features_df, n_particles=20, n_iter=50, cv=3, save_csv=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0fe05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMU Env (3.13.5)",
   "language": "python",
   "name": "visenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
